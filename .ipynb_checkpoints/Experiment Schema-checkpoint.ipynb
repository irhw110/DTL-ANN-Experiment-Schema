{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed library\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load iris dataset\n",
    "data_iris = load_iris()\n",
    "iris_X, iris_y = load_iris(return_X_y=True)\n",
    "feature_iris = data_iris['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform iris into dataframe\n",
    "iris_X=pd.DataFrame(iris_X)\n",
    "iris_y=pd.DataFrame(iris_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create index so be merge\n",
    "iris_X=iris_X.reset_index()\n",
    "iris_y=iris_y.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_y.rename(columns = {0:4}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge dataset iris\n",
    "iris=iris_X.merge(iris_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop index\n",
    "iris.drop(\"index\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.rename(columns = {0:feature_iris[0],1:feature_iris[1],2:feature_iris[2],3:feature_iris[3],4:\"target\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(parsed_data, target_attribute):\n",
    "    parsed_value_target = {}\n",
    "    total_value_target = 0\n",
    "  \n",
    "    for i in parsed_data[target_attribute]:\n",
    "        if i is not None:\n",
    "            if i not in parsed_value_target:\n",
    "                parsed_value_target[i] = 1\n",
    "            else:\n",
    "                parsed_value_target[i] += 1\n",
    "\n",
    "            total_value_target += 1\n",
    "  \n",
    "    log_result = 0\n",
    "\n",
    "    for i in parsed_value_target:\n",
    "        log_result += float(parsed_value_target[i])/total_value_target * math.log((float(parsed_value_target[i])/total_value_target), 2)\n",
    "  \n",
    "    return -1 * log_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasn't handle after universal entropy\n",
    "def information_gain(data, gain_attribute, target_attribute):\n",
    "    gain_result = 0\n",
    "    attribute_entropy_result = 0\n",
    "    parsed_attribute_count = {}\n",
    "    total_attribute_count = 0\n",
    "    \n",
    "    for i in data[gain_attribute]:\n",
    "        if i is not None:\n",
    "            if i not in parsed_attribute_count:\n",
    "                parsed_attribute_count[i] = 1\n",
    "            else:\n",
    "                parsed_attribute_count[i] += 1\n",
    "            \n",
    "            total_attribute_count += 1\n",
    "    \n",
    "    for i in parsed_attribute_count:\n",
    "        parsed_data = data.loc[data[gain_attribute]==i]\n",
    "        attribute_entropy_result += float(parsed_attribute_count[i])/total_attribute_count * entropy(parsed_data, target_attribute)    \n",
    "\n",
    "    gain_result += entropy(data,target_attribute) + (-1 * attribute_entropy_result)\n",
    "    return gain_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_information(data, gain_attribute):\n",
    "    res = entropy(data, gain_attribute)\n",
    "    if(res==0):\n",
    "        res=0.00000001\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_ratio(data, gain_attribute, target_attribute):\n",
    "    res = information_gain(data, gain_attribute, target_attribute) / split_information(data, gain_attribute)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_ratio_continous(data, gain_attribute, target_attribute):\n",
    "    res = information_gain_continous(data, gain_attribute, target_attribute)[0] / split_information(data, gain_attribute)\n",
    "    return res,information_gain_continous(data, gain_attribute, target_attribute)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_attribute(data,target_attribute,is_IG):\n",
    "    gain_attribute = {\n",
    "        'value': 0,\n",
    "        'name': ''\n",
    "    }\n",
    "    \n",
    "    \n",
    "    for i in data.columns:\n",
    "        if (i != target_attribute):\n",
    "            if is_IG:\n",
    "                if information_gain(data, i, target_attribute) > gain_attribute['value']:\n",
    "                    gain_attribute['value'] = information_gain(data, i, target_attribute)\n",
    "                    gain_attribute['name'] = i\n",
    "            else:\n",
    "                if gain_ratio(data, i, target_attribute) > gain_attribute['value']:\n",
    "                    gain_attribute['value'] = gain_ratio(data, i, target_attribute)\n",
    "                    gain_attribute['name'] = i\n",
    "                \n",
    "\n",
    "    return gain_attribute['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, attribute=None, label=None, vertex=None):\n",
    "        self.attribute = attribute\n",
    "        self.label = label\n",
    "        self.vertex = vertex\n",
    "        self.children = {}\n",
    "        self.most_common_label = None\n",
    "    \n",
    "    def set_most_common_label(self, most_common_label):\n",
    "        self.most_common_label = most_common_label\n",
    "        \n",
    "    def get_most_common_label(self):\n",
    "        return self.most_common_label\n",
    "        \n",
    "    def setAttribute(self, attribute):\n",
    "        self.attribute = attribute\n",
    "\n",
    "    def setLabel(self, label):\n",
    "        self.label = label\n",
    "        \n",
    "    def setVertex(self, vertex):\n",
    "        self.vertex = vertex\n",
    "  \n",
    "    def addChildren(self, attributeValue, node):\n",
    "        self.children[attributeValue] = node\n",
    "    \n",
    "    def getChildren(self):\n",
    "        return self.children\n",
    "    \n",
    "    def getLabel(self):\n",
    "        return self.label\n",
    "    \n",
    "    def getVertex(self):\n",
    "        return self.vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_label(data, target_attribute):\n",
    "    parsed_value_target = {}\n",
    "  \n",
    "    for i in data[target_attribute]:\n",
    "        if i is not None:\n",
    "            if i not in parsed_value_target:\n",
    "                parsed_value_target[i] = 1\n",
    "            else:\n",
    "                parsed_value_target[i] += 1\n",
    "\n",
    "    most_common = {\n",
    "        'value': 0,\n",
    "        'name': ''\n",
    "    }\n",
    "    \n",
    "    for i in parsed_value_target:\n",
    "        if parsed_value_target[i] > most_common['value']:\n",
    "            most_common['value'] = parsed_value_target[i]\n",
    "            most_common['name'] = i\n",
    "    \n",
    "    return most_common['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_label_target(data,target_attribute):\n",
    "    most_comm = None\n",
    "    occ = 0;\n",
    "    for i in data[target_attribute].unique():\n",
    "        if data[data[target_attribute] == i].shape[0] >  occ:\n",
    "            most_comm = i\n",
    "            occ = data[data[target_attribute] == i].shape[0]\n",
    "    return most_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(data, target_attribute, is_IG):\n",
    "    node = Node()\n",
    "    if data[target_attribute].nunique()==1:\n",
    "        node.setLabel(data[target_attribute].unique()[0])\n",
    "        return node\n",
    "    \n",
    "    elif len(data.columns)==1:\n",
    "        node.setLabel(get_most_common_label(data, target_attribute))\n",
    "        return node\n",
    "    \n",
    "    else:\n",
    "        best_attribute_ = best_attribute(data,target_attribute,is_IG)\n",
    "        node.setAttribute(best_attribute_)\n",
    "        for i in data[best_attribute_].unique():\n",
    "            node.addChildren(i,id3(data.loc[data[best_attribute_]==i],target_attribute,is_IG))\n",
    "            node.set_most_common_label(most_common_label_target(data,target_attribute))        \n",
    "            \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node,depth):\n",
    "    if node.label is not None: \n",
    "        print(\"    \"*(depth+1) +str(node.label))\n",
    "    else:\n",
    "        print(\"    \"*depth + \"[\"+ node.attribute +\"]\")\n",
    "        for i in node.children:\n",
    "            print(\"----\"*(depth+1) +str(i))\n",
    "            print_tree(node.children[i],depth+1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_tree(node):\n",
    "    temp_node = Node()\n",
    "    if node.label is not None: \n",
    "        temp_node.setLabel(node.label)\n",
    "    else:\n",
    "        temp_node.setAttribute(node.attribute)\n",
    "        for i in node.children:\n",
    "            temp= Node()\n",
    "            temp= node.children[i]\n",
    "            temp_node.addChildren(i, temp)\n",
    "    return temp_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tree(node,data,index,result, target_attribute):\n",
    "    if node.label is not None: \n",
    "        result.append(node.getLabel())\n",
    "    else:\n",
    "        if data.loc[index, node.attribute] is None:\n",
    "            result.append(node.get_most_common_label())\n",
    "        for i in node.children:\n",
    "            if i==data.loc[index,node.attribute]:\n",
    "                check_tree(node.children[i],data,index,result, target_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(data,model,target_attribute):\n",
    "    result = []\n",
    "    for i in range(len(data)):\n",
    "        check_tree(model,data[i:i+1],i,result, target_attribute)\n",
    "    data = {target_attribute:result}\n",
    "    return pd.DataFrame(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasn't handle after universal entropy\n",
    "def information_gain_continous(data, gain_attribute, target_attribute):\n",
    "    gain_result = 0\n",
    "    save_boundary = -1\n",
    "    min_entropy = 999999 \n",
    "    data = data.sort_values(gain_attribute)\n",
    "    data=data.reset_index().drop('index',axis=1)\n",
    "    length_data = len(data)\n",
    "    for i in range(length_data):\n",
    "        if (i!=length_data-1):\n",
    "            if (data.loc[i,target_attribute] != data.loc[i+1,target_attribute]):\n",
    "                temp_boundary = (data.loc[i,gain_attribute] + data.loc[i+1,gain_attribute])/2\n",
    "                parsed_data_upper = data.loc[data[gain_attribute]>=temp_boundary]\n",
    "                parsed_data_lower = data.loc[data[gain_attribute]<temp_boundary]\n",
    "                len_parsed = len(parsed_data_upper)               \n",
    "                temp_entropy = float(len_parsed)/length_data * entropy(parsed_data_upper, target_attribute) + float((length_data-len_parsed))/length_data * entropy(parsed_data_lower, target_attribute)     \n",
    "                if temp_entropy < min_entropy:\n",
    "                    #print(gain_attribute, temp_boundary, temp_entropy)\n",
    "                    min_entropy = temp_entropy \n",
    "                    save_boundary = temp_boundary\n",
    "\n",
    "    gain_result += entropy(data,target_attribute) + (-1 * min_entropy)\n",
    "    return gain_result,save_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9182958340544894, 2.45)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_gain_continous(iris, 'petal length (cm)', 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_attribute_c45(data,target_attribute,is_IG):\n",
    "    gain_attribute = {\n",
    "        'value': 0,\n",
    "        'name': '',\n",
    "        'boundary': -99999999\n",
    "    }\n",
    "    \n",
    "    \n",
    "    for i in data.columns:\n",
    "        if (i != target_attribute):\n",
    "            if is_IG:\n",
    "                if data[i].dtypes in [pd.np.dtype('float64'), pd.np.dtype('float32')]:\n",
    "                    ig = information_gain_continous(data, i, target_attribute) \n",
    "                    if ig[0] > gain_attribute['value']:\n",
    "                            gain_attribute['value'] = ig[0]\n",
    "                            gain_attribute['name'] = i\n",
    "                            gain_attribute['boundary'] = ig[1]\n",
    "                else:\n",
    "                    if information_gain(data, i, target_attribute) > gain_attribute['value']:\n",
    "                            gain_attribute['value'] = information_gain(data, i, target_attribute)\n",
    "                            gain_attribute['name'] = i\n",
    "            else:\n",
    "                if data[i].dtypes in [pd.np.dtype('float64'), pd.np.dtype('float32')]:\n",
    "                    ig = gain_ratio_continous(data, i, target_attribute) \n",
    "                    if ig[0] > gain_attribute['value']:\n",
    "                            gain_attribute['value'] = ig[0]\n",
    "                            gain_attribute['name'] = i\n",
    "                            gain_attribute['boundary'] = ig[1]\n",
    "                else:\n",
    "                    if gain_ratio(data, i, target_attribute) > gain_attribute['value']:\n",
    "                            gain_attribute['value'] = gain_ratio(data, i, target_attribute)\n",
    "                            gain_attribute['name'] = i\n",
    "\n",
    "    return gain_attribute['name'],round(gain_attribute['boundary'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('petal width (cm)', 0.8)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_attribute_c45(iris,'target',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c45(data, target_attribute,is_IG):\n",
    "    node = Node()\n",
    "    if data[target_attribute].nunique()==1:\n",
    "        node.setLabel(data[target_attribute].unique()[0])\n",
    "        return node\n",
    "    \n",
    "    elif len(data.columns)==1:\n",
    "        node.setLabel(get_most_common_label(data, target_attribute))\n",
    "        return node\n",
    "    \n",
    "    else:\n",
    "        best_attribute_,bound  = best_attribute_c45(data,target_attribute,is_IG)\n",
    "        #print(best_attribute_)\n",
    "        node.setAttribute(best_attribute_)\n",
    "        node.set_most_common_label(most_common_label_target(data,target_attribute))\n",
    "        if bound==-99999999:\n",
    "            for i in data[best_attribute_].unique():\n",
    "                node.addChildren(i,c45(data.loc[data[best_attribute_]==i],target_attribute,is_IG))\n",
    "        else:\n",
    "            node.addChildren('>='+str(bound),c45(data.loc[data[best_attribute_]>=bound],target_attribute,is_IG))\n",
    "            node.addChildren('<'+str(bound),c45(data.loc[data[best_attribute_]<bound],target_attribute,is_IG))\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c45_prun(data, target_attribute,is_IG,vertex_=None):\n",
    "    node = Node(vertex = vertex_)\n",
    "    if data[target_attribute].nunique()==1:\n",
    "        node.setLabel(data[target_attribute].unique()[0])\n",
    "        return node\n",
    "     \n",
    "    elif len(data.columns)==1:\n",
    "        node.setLabel(get_most_common_label(data, target_attribute))\n",
    "        return node\n",
    "    \n",
    "    else:\n",
    "        best_attribute_,bound  = best_attribute_c45(data,target_attribute,is_IG)\n",
    "        #print(best_attribute_)\n",
    "        node.setAttribute(best_attribute_)\n",
    "        node.set_most_common_label(most_common_label_target(data,target_attribute))\n",
    "        if bound==-99999999:\n",
    "            for i in data[best_attribute_].unique():\n",
    "                node.addChildren(i,c45_prun(data.loc[data[best_attribute_]==i],target_attribute,is_IG,i))\n",
    "        else:\n",
    "            node.addChildren('>='+str(bound),c45_prun(data.loc[data[best_attribute_]>=bound],target_attribute,is_IG,'>='+str(bound)))\n",
    "            node.addChildren('<'+str(bound),c45_prun(data.loc[data[best_attribute_]<bound],target_attribute,is_IG,'<'+str(bound)))\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Node at 0x252359f6448>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c45(iris, \"target\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[petal length (cm)]\n",
      "---->=2.45\n",
      "    [petal width (cm)]\n",
      "-------->=1.75\n",
      "        [sepal width (cm)]\n",
      "------------>=3.15\n",
      "            [sepal length (cm)]\n",
      "---------------->=6.05\n",
      "                    2\n",
      "----------------<6.05\n",
      "                    1\n",
      "------------<3.15\n",
      "                2\n",
      "--------<1.75\n",
      "        [petal length (cm)]\n",
      "------------>=4.95\n",
      "            [petal width (cm)]\n",
      "---------------->=1.55\n",
      "                [sepal length (cm)]\n",
      "-------------------->=6.95\n",
      "                        2\n",
      "--------------------<6.95\n",
      "                        1\n",
      "----------------<1.55\n",
      "                    2\n",
      "------------<4.95\n",
      "            [petal width (cm)]\n",
      "---------------->=1.65\n",
      "                    2\n",
      "----------------<1.65\n",
      "                    1\n",
      "----<2.45\n",
      "        0\n"
     ]
    }
   ],
   "source": [
    "print_tree(c45(iris, \"target\",True),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tree_c45(node,data,index,result, target_attribute):\n",
    "    if node.label is not None: \n",
    "        result.append(node.getLabel())\n",
    "    else:\n",
    "        if data.loc[index, node.attribute] is None:\n",
    "            result.append(node.get_most_common_label())\n",
    "        else:\n",
    "            for i in node.children:\n",
    "                #print(i)\n",
    "                if i[0]=='<':\n",
    "                    #print(i,2)\n",
    "                    bound=float(i[1:])\n",
    "                    if bound>data.loc[index,node.attribute]:\n",
    "                        #print(data.loc[index,node.attribute])\n",
    "                        check_tree_c45(node.children[i],data,index,result, target_attribute)\n",
    "                elif i[0]=='>':\n",
    "                    bound=float(i[2:])\n",
    "                    #print(i,1)\n",
    "                    if bound<=data.loc[index,node.attribute]:\n",
    "                        #print(data.loc[index,node.attribute])\n",
    "                        check_tree_c45(node.children[i],data,index,result, target_attribute)\n",
    "                else:\n",
    "                    if i==data.loc[index,node.attribute]:\n",
    "                        check_tree(node.children[i],data,index,result, target_attribute)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_c45(data,model,target_attribute):\n",
    "    result = []\n",
    "    for i in range(len(data)):\n",
    "        check_tree_c45(model,data[i:i+1],i,result, target_attribute)\n",
    "    data = { target_attribute: data[target_attribute]\n",
    "            ,'prediction':result}\n",
    "    return pd.DataFrame(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=p.drop('target',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=p.reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['sepal width (cm)'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred,data):\n",
    "    cnt = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred.loc[i] == data.loc[i]:\n",
    "            cnt+=1\n",
    "    return cnt*100/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_validate(data):\n",
    "    data_column = data.columns\n",
    "    data_10 = pd.DataFrame(columns=data_column)\n",
    "    data_90 = pd.DataFrame(columns=data_column)\n",
    "    print(data_column)\n",
    "    count_10 = 0\n",
    "    count_90 = 0\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        if(i%10 == 1):\n",
    "            # Pass the row elements as key value pairs to append() function \n",
    "            data_10 = data_10.append(data.loc[[i]] , ignore_index=True)\n",
    "        else:\n",
    "            data_90 = data_90.append(data.loc[[i]] , ignore_index=True)\n",
    "    return data_10, data_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_tree(node, attribute, vertex):\n",
    "    if(node.label is not None):\n",
    "        return node,0\n",
    "    elif(node.attribute == attribute and node.vertex == vertex):\n",
    "        node.children = {}\n",
    "        node.attribute = None\n",
    "        node.label = node.most_common_label\n",
    "        \n",
    "        return node,1\n",
    "    else:\n",
    "        for i in node.children:\n",
    "            a,b = prune_tree(node.children[i], attribute, vertex)\n",
    "            \n",
    "        return node,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_pruning(data, node, current_node, children_node, target_attribute):\n",
    "    if children_node == 0:\n",
    "        return node\n",
    "    else:\n",
    "        for i in current_node.children:\n",
    "            if current_node.vertex is None: \n",
    "                #print(i,1)\n",
    "                post_pruning(data, node, current_node.children[i], children_node-1, target_attribute)\n",
    "            else:\n",
    "                if current_node.attribute is not None:\n",
    "                    data10, data90 = get_data_validate(data)\n",
    "                    #print(current_node.attribute,2)\n",
    "                    save = copy_tree(current_node)\n",
    "                    temp_node,c = prune_tree(node, current_node.attribute, current_node.vertex)\n",
    "                    train=data90.drop(target_attribute,axis=1)\n",
    "                    #print_tree(node,0)\n",
    "                    temp_node_pred = pred_c45(train, node, target_attribute)\n",
    "                    #print(temp_node_pred)\n",
    "                    temp_node_accuracy = accuracy(temp_node_pred[target_attribute], data90[target_attribute])\n",
    "                    #print(temp_node_accuracy)\n",
    "                    if temp_node_accuracy == 100:\n",
    "                        post_pruning(data, temp_node, current_node, children_node, target_attribute)\n",
    "                    else :\n",
    "                        \n",
    "                        node.addChildren(current_node.vertex, save)\n",
    "                        #print_tree(node,0)\n",
    "\n",
    "\n",
    "                        post_pruning(data, node, save.children[i], children_node, target_attribute)\n",
    "        return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################          ANN              ###################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(x):\n",
    "    if (x>0.5):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_error(target, output):\n",
    "    return 0.5*(target-output)*(target-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, out=None, w=None, is_used=None, error=None):\n",
    "        self.out = out\n",
    "        self.w = []\n",
    "        self.is_used = is_used\n",
    "        self.error = 0\n",
    "        self.deltaW = []\n",
    "        \n",
    "    def set_out(self, out):\n",
    "        self.out = out\n",
    "        \n",
    "    def get_out(self):\n",
    "        return self.out\n",
    "    \n",
    "    def add_deltaW(self, value):\n",
    "        self.deltaW.append(value)\n",
    "        \n",
    "    def get_deltaW(self, index):\n",
    "        return self.deltaW[index]\n",
    "    \n",
    "    def get_arrdW(self):\n",
    "        return self.deltaW\n",
    "    \n",
    "    def set_deltaW(self, index, value):\n",
    "        self.deltaW[index] = value\n",
    "        \n",
    "    def add_w(self, value):\n",
    "        self.w.append(value)\n",
    "        \n",
    "    def set_w(self, index, value):\n",
    "        self.w[index] = value\n",
    "    \n",
    "    def get_w(self, index):\n",
    "        return self.w[index]\n",
    "    \n",
    "    def get_arrW(self):\n",
    "        return self.w\n",
    "    \n",
    "    def set_is_used(self, is_used):\n",
    "        self.is_used = is_used\n",
    "        \n",
    "    def get_is_used(self):\n",
    "        return self.is_used\n",
    "    \n",
    "    def set_error(self, error):\n",
    "        self.error = error\n",
    "    \n",
    "    def get_error(self):\n",
    "        return self.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [Neuron() for i in range (5)]\n",
    "y = [x for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LenCol(arr):\n",
    "    return len(arr)\n",
    "def LenRow(inp,hid,out):\n",
    "    return max(inp,max(hid)+1,out)\n",
    "def MakeMatrix(row,col):\n",
    "    return [[Neuron() for i in range (col)] for j in range(row)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMatrixMLP(matrix):\n",
    "    for i in range(len(matrix)):\n",
    "        temp_matrix_out = []\n",
    "        for j in range(len(matrix[i])):\n",
    "            temp_matrix_out.append(matrix[i][j].get_arrW())\n",
    "        print(temp_matrix_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convTarget(output,unique):\n",
    "    res = []\n",
    "    for i in range(unique):\n",
    "        if (i!=output):\n",
    "            res.append(0)\n",
    "        else:\n",
    "            res.append(1)\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetDeltaWeight(mat,layer):\n",
    "    for i in range(len(layer)-1):\n",
    "        for j in range(layer[i]):\n",
    "            for k in range(layer[i+1]):\n",
    "                mat[j][i].set_deltaW(k,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initW(mat,layer):\n",
    "    for i in range(len(layer)-1):\n",
    "        for j in range(layer[i]):\n",
    "            for k in range(layer[i+1]):\n",
    "                mat[j][i].add_w(np.random.uniform(-1,1)) \n",
    "                mat[j][i].add_deltaW(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(mat,layer):\n",
    "    for i in range(1,len(layer)):\n",
    "        if (i!=len(layer)-1):\n",
    "            mat[layer[i]][i].set_out(1)\n",
    "        for j in range(layer[i]):\n",
    "            net = 0;\n",
    "            for k in range(layer[i-1]):\n",
    "                #print(k,i-1,j)\n",
    "                net = net + mat[k][i-1].get_out()*mat[k][i-1].get_w(j)\n",
    "#             if (i!=len(layer)-1):\n",
    "            mat[j][i].set_out(sigmoid(net))\n",
    "#             else:\n",
    "#                 mat[j][i].set_out(sign(sigmoid(net)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_total(matrix, n_output, target_arr):\n",
    "    output_col = len(matrix[0])-1\n",
    "    total_error = 0\n",
    "    for i in range(n_output):\n",
    "        total_error += 0.5*(target_arr[i] - matrix[i][output_col].get_out())**2\n",
    "    \n",
    "    return total_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_output_error(matrix, row, col, target_value):\n",
    "    output_value = matrix[row][col].get_out()\n",
    "    #print(output_value, target_value)\n",
    "#     print(output_value * (1 - output_value) * (target_value - output_value))\n",
    "    matrix[row][col].set_error(output_value * (1 - output_value) * (target_value - output_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_hidden_error(matrix, row, col):\n",
    "    output_value = matrix[row][col].get_out()\n",
    "    delta_weight_error = 0\n",
    "    for i in range(len(matrix[row][col].w)):\n",
    "        delta_weight_error += matrix[row][col].get_w(i) * matrix[i][col+1].get_error()\n",
    "    matrix[row][col].set_error(output_value * (1 - output_value) * delta_weight_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_delta_weight(matrix, row, col, idx , learning_rate):\n",
    "    #print(matrix[i][col+1].get_error(),matrix[row][col].get_out(),row,col)\n",
    "    #print(row,col+1)\n",
    "    delta_weight = learning_rate * matrix[row][col].get_error() * matrix[idx][col-1].get_out()\n",
    "    #print(delta_weight)\n",
    "    \n",
    "    current_weight = matrix[idx][col-1].get_deltaW(row)\n",
    "    matrix[idx][col-1].set_deltaW(row, current_weight + delta_weight)\n",
    "    #print(idx,col-1,row,current_weight + delta_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weight(mat,layer):\n",
    "    for i in range(len(layer)-1):\n",
    "        for j in range(layer[i]):\n",
    "            for k in range(layer[i+1]):\n",
    "                curr_weight = mat[j][i].get_w(k)\n",
    "                delta_weight = mat[j][i].get_deltaW(k)\n",
    "                mat[j][i].set_w(k,curr_weight + delta_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(matrix, layer, learning_rate, target_arr):\n",
    "    for i in range(len(layer)-1, 0, -1):\n",
    "        if i == len(layer)-1:\n",
    "            for j in range(layer[i]):\n",
    "                set_output_error(matrix, j, i, target_arr[j])\n",
    "        else:\n",
    "            for j in range(layer[i]):\n",
    "                set_hidden_error(matrix, j, i)\n",
    "        for j in range(layer[i-1]):\n",
    "            for k in range(layer[i]):\n",
    "                update_delta_weight(matrix, k, i, j, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_node = [3,4]\n",
    "def MLP(data,target, hidden_node, epochs, learning_rate):\n",
    "    output_node = data[target].nunique()\n",
    "    input_node = len(data.columns)\n",
    "    hidden_node.insert(0,input_node)\n",
    "    hidden_node.append(output_node)\n",
    "    layer_node = hidden_node\n",
    "    mlp = MakeMatrix(LenRow(input_node,hidden_node,output_node),LenCol(hidden_node))\n",
    "    initW(mlp,layer_node)\n",
    "    train = data.drop(target,axis=1)\n",
    "    batch = len(data)/10;\n",
    "    for k in range(epochs):\n",
    "        error = 0\n",
    "        for i in range(int(batch)):\n",
    "            for j in range(10):\n",
    "                for index,col in enumerate(train.columns):\n",
    "                    mlp[index][0].set_out(data[col][j+i*10])\n",
    "                mlp[input_node-1][0].set_out(1)\n",
    "                feedforward(mlp,layer_node)\n",
    "                backpropagation(mlp, layer_node, learning_rate, convTarget(data[target][j+i*10],output_node))\n",
    "                error += get_error_total(mlp, len(convTarget(data[target][j+i*10],output_node)), convTarget(data[target][j+i*10],output_node))\n",
    "            update_weight(mlp,layer_node)\n",
    "            resetDeltaWeight(mlp,layer_node)\n",
    "        print(error)\n",
    "    print()\n",
    "    print()\n",
    "    printMatrixMLP(mlp)\n",
    "\n",
    "    return mlp,layer_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predMyMLP(data, target, model, output_layer):\n",
    "    out = []\n",
    "    mlp = model[0]\n",
    "    for i in range(0,data.shape[0],1):\n",
    "        for index,col in enumerate(data.columns):\n",
    "            mlp[index][0].set_out(data[col][i])\n",
    "        mlp[len(data.columns)-1][0].set_out(1)\n",
    "        feedforward(mlp,model[1])\n",
    "        output_col = len(mlp[0])-1\n",
    "        #print(output_col)\n",
    "        mx=0\n",
    "        res=-1\n",
    "        for j in range(output_layer):\n",
    "            # print(mlp[j][output_col].get_out())\n",
    "            if mlp[j][output_col].get_out()>mx:\n",
    "                mx = mlp[j][output_col].get_out()\n",
    "                res = j\n",
    "        # print()\n",
    "        out.append(res)\n",
    "    data = { target: data[target],\n",
    "             'prediction':out}\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################       Testing                ############################################\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = iris['target'].unique()\n",
    "\n",
    "# Create confusion matrix from testing result of a model\n",
    "#\n",
    "# Input:\n",
    "#    pandas.DataFrame   prediction_data\n",
    "#    String             actual_column\n",
    "#    String             prediction_column\n",
    "#    Array              class_list\n",
    "# Output:\n",
    "#    pandas.DataFrame   confusion_matrix\n",
    "#\n",
    "def confusion_matrix(prediction_data, actual_column, prediction_column, class_list):\n",
    "    actual_data = pd.Categorical(prediction_data[actual_column], categories=class_list)\n",
    "    prediction_data = pd.Categorical(prediction_data[prediction_column], categories=class_list)\n",
    "    confusion_matrix = pd.crosstab(actual_data, prediction_data, rownames=['Actual'], colnames=['Predicted'], dropna=False)\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy from testing result of a model\n",
    "#\n",
    "# Input:\n",
    "#    pandas.DataFrame   prediction_data\n",
    "#    String             actual_column\n",
    "#    String             prediction_column\n",
    "# Output:\n",
    "#    float              accuracy\n",
    "#\n",
    "def testing_accuracy(prediction_data, actual_column, prediction_column):\n",
    "    count = 0\n",
    "    for index, row in prediction_data.iterrows():\n",
    "        if(row[actual_column] == row[prediction_column]):\n",
    "            count = count + 1\n",
    "    return round(count/prediction_data.shape[0],2)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
      "       'petal width (cm)', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "################################# Testing DTL\n",
    "\n",
    "data10, data90 = get_data_validate(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target  prediction\n",
      "0       0           0\n",
      "1       0           0\n",
      "2       0           0\n",
      "3       0           0\n",
      "4       0           0\n",
      "5       1           1\n",
      "6       1           1\n",
      "7       1           1\n",
      "8       1           1\n",
      "9       1           1\n",
      "10      2           2\n",
      "11      2           2\n",
      "12      2           2\n",
      "13      2           2\n",
      "14      2           2\n"
     ]
    }
   ],
   "source": [
    "model = c45(data90, \"target\",True)\n",
    "prediction_dtl = pred_c45(data10, model, \"target\")\n",
    "print(prediction_dtl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  0  1  2\n",
      "Actual            \n",
      "0          5  0  0\n",
      "1          0  5  0\n",
      "2          0  0  5\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(prediction_dtl,'target','prediction', class_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_accuracy(prediction_dtl,'target','prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
      "       'petal width (cm)', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "################################# Testing ANN\n",
    "\n",
    "data10, data90 = get_data_validate(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.48833568538582\n",
      "42.70822347567036\n",
      "42.17112666386392\n",
      "41.322791769832385\n",
      "40.18618523469346\n",
      "38.78060296040001\n",
      "37.15120618586272\n",
      "35.38264788976741\n",
      "33.59117993317013\n",
      "31.895192919849784\n",
      "30.380920190747304\n",
      "29.087278737784914\n",
      "28.014582946769583\n",
      "27.14061815364156\n",
      "26.433710578208675\n",
      "25.86161998720369\n",
      "25.396111291572364\n",
      "25.01424179158375\n",
      "24.698021115329844\n",
      "24.4335486568903\n",
      "\n",
      "\n",
      "[[-0.6520824043288473, -0.12612749884421393, 0.2210515977947524], [0.6633886940261726, -0.3650212436314327, -0.24443709848412093, -0.7575671954059494], [2.839182504468756, -1.6060814401359975, -2.7322495616122895], []]\n",
      "[[-1.001130841374595, 0.5685113400327318, 1.4587787322843395], [-1.241129851270293, -0.6688519979542902, 0.3280170819873375, 0.7236020441293947], [-1.3362187429670123, -0.7776377873497242, 0.36164543904694624], []]\n",
      "[[-0.08209304572818477, 0.8290279389938202, -1.669375059576119], [3.3091490573107816, -1.125337720735463, -1.3809977795358372, -2.636232444568098], [-1.809452710828952, -0.46048108644855484, -0.35130904923749307], []]\n",
      "[[0.6389364914591438, 0.9177976447745523, -1.3329088862344332], [], [-2.1865864589309236, 1.0120807535442018, 1.5252693204557173], []]\n",
      "[[0.5627114101406763, 0.7609007207482836, 0.20474973924661893], [], [], []]\n",
      "[[], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "hidden_node = [3,4]\n",
    "x = MLP(data90, 'target', hidden_node,20,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target  prediction\n",
      "0       0           0\n",
      "1       0           0\n",
      "2       0           0\n",
      "3       0           0\n",
      "4       0           0\n",
      "5       1           2\n",
      "6       1           2\n",
      "7       1           2\n",
      "8       1           2\n",
      "9       1           2\n",
      "10      2           2\n",
      "11      2           2\n",
      "12      2           2\n",
      "13      2           2\n",
      "14      2           2\n"
     ]
    }
   ],
   "source": [
    "prediction_ann = predMyMLP(data10, 'target', x, 3)\n",
    "print(prediction_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  0  1  2\n",
      "Actual            \n",
      "0          5  0  0\n",
      "1          0  0  5\n",
      "2          0  0  5\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(prediction_ann,'target','prediction', class_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_accuracy(prediction_ann,'target','prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
